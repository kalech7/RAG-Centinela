\chapter{Introducción}

\section{Planteamiento del problema}

\section{Justificación}

\section{Justificación Metodológica}

\section{Objetivos}
\subsection{Objetivo general}
Desarrollar e implementar un sistema RAG que mejore el desempeño del buscador de la plataforma
Centinela, permitiendo recuperar información científica relevante y generar respuestas automáticas
de valor para el usuario.
\subsection{Objetivos específicos}
\begin{itemize}[align=left, label=-]
    \item Realizar una revisión sistemática de la literatura sobre metodologías y/o frameworks para la implementación de RAG.
    \item Diseñar e implementar la arquitectura técnica del sistema RAG utilizando modelos de recuperación y generación de texto.
    \item Evaluar el sistema RAG desarrollado mediante métricas estándar.
\end{itemize}

\section{Alcance}

\section{Marco Teórico}

\section{Revision de literatura}
En los últimos años, la evolución de los modelos de lenguaje de gran escala (Large Language Models, LLM) han redefinido el procesamiento del lenguaje natural
e impulsado nuevas líneas de investigación. 
Sin embargo, estos modelos dependen únicamente de los datos empleados durante su entrenamiento, lo que limita su capacidad para ofrecer respuestas actualizadas, verificables y 
contextualizadas. En respuesta a esta limitación surge el enfoque de Retrieval-Augmented Generation (RAG), el cual combina la recuperación de información con la generación de 
lenguaje natural, logrando mejorar la precisión, la coherencia y la actualidad de las respuestas producidas por los modelos.

Dada la creciente relevancia de los LLM, resulta necesario llevar a cabo una revisión exhaustiva de la literatura que permita consolidar los avances recientes y evaluar los desafíos aún presentes.
En esta sección se presenta un análisis estructurado de la literatura disponible, considerando tanto los fundamentos conceptuales de RAG como sus fases de desarrollo, 
aplicaciones y el futuro. Para ello, el proceso de revisión se organiza en las fases que se presentan a continuación, las cuales buscan garantizar la consistencia, validez 
y pertinencia de la evidencia obtenida.

\subsection{Propósito y objetivos de la revisión}
El propósito de esta revisión es consolidar la información disponible sobre los RAG, abordando su estudio desde los fundamentos hasta las fases de desarrollo. 
Se inicia con su definición y arquitectura, para luego profundizar en las etapas clave del proceso: Extracción del corpus, preprocesamiento, vectorización, recuperación de información, 
evaluación, almacenamiento en bases vectoriales y generación de resultados. Asimismo, se examinan los paradigmas, las métricas de evaluación y el futuro de RAG.
Durante esta revision se busca lograr el objetivo general de proporcionar un panorama global y actualizado sobre los RAG,
exponiendo sus fundamentos, desarrollo y aplicación.

\subsection{Criterios de inclusión y exclusión}
Se incluyen únicamente revisiones sistemáticas y metaanálisis publicados entre 2018 y 2025, en inglés o español, dado que la producción 
científica en el área comenzó a incrementarse a partir de 2018, con base en información de Lens.org\footnote{Es una plataforma abierta
para la búsqueda, análisis y visualización de literatura científica y patentes. Accesible en: \href{https://www.lens.org/}{Lens.org}}, este incremento coincide
con la popularización 
de los modelos de lenguaje basados en transformers\footnote{Se atribuye a hitos como BERT (2018), GPT-2 (2019) y T5 (2020), que impulsaron un avance 
en la investigación del procesamiento del Lenguaje Natural}.
Los estudios deben provenir de fuentes confiables y ser, a su vez, revisados por 
un experto. Se da preferencia a aquellos que presenten una cobertura amplia de los temas más relevantes para el objeto de estudio.  

Se excluyen las revisiones narrativas, los documentos que carezcan de transparencia en sus métodos de búsqueda o síntesis, así como las publicaciones que no estén 
directamente relacionadas con el objeto de estudio delimitado.

\subsection{Identificación del estudio semilla y selección de revisiones relevantes}
El proceso de búsqueda se inicia con la identificación de dos estudios semilla, extraídos de Google Scholar mediante los parámetros “retrieval information” y “retrieval augmented generation”. 
Debido al análisis realizado en Lens.org, se estableció el filtro de 2018 a 2025, ya que se observa que a partir de 2018 el término retrieval-augmented generation 
comenzó a adquirir una relevancia en la literatura científica, mostrando interés de la comunidad investigadora hasta la actualidad.

El primer estudio seleccionado fue Information Retrieval: Recent Advances and Beyond (Hambarde \& Proença, 2023), publicado en IEEE Access. 
Este trabajo constituye una revisión exhaustiva de la recuperación de información, abarcando desde los métodos tradicionales hasta los enfoques 
basados en deep learning y transformers, por lo que resulta un punto de partida principal para explorar la literatura reciente y relevante.

El segundo estudio semilla corresponde al artículo Retrieval-Augmented Generation for Large Language Models (Gao, Xiong, Gao, Jia, Pan, Bi, Dai, Sun \& Wang, 2023), publicado en
arXiv,
el cual presenta un marco conceptual y aplicado sobre la integración de recuperación de información y modelos generativos de gran escala. Su incorporación permite 
establecer una base teórica para contextualizar el análisis de las revisiones seleccionadas.

A partir de estos dos estudios semilla, y aplicando los criterios de inclusión y exclusión previamente definidos, se identificaron \textcolor{blue}{25} revisiones 
relevantes que cumplen con los criterios establecidos. 
Estas revisiones constituyen la base para el análisis y síntesis en el presente trabajo.



\subsection{Valoracion de la evidencias y extracion de la infomacion}
De los estudios seleccionados se procede a realizar un análisis, 
con el fin de excluir aquellos artículos que no cumplen con los criterios establecidos 
o que presentan un nivel de profundidad insuficiente para los objetivos de la revisión. 
La selección final de los estudios se realiza en consenso con expertos en el área, 
garantizando así la pertinencia y relevancia de la evidencia incluida.Para la organización, codificación y síntesis de la 
información se usa ATLAS.ti \footnote{Scientific Software Development GmbH. Disponible en: \href{https://atlasti.com/es}{Atlas.ti}} que facilitará la estructuración de los hallazgos.





% para resuemir la informacion se uso (herramienta) atlas por ejemplo

\subsection{Síntesis y representación de resultados}
Con la literatura seleccionada se identificó la hoja de ruta que se presenta a continuación en la Figura \ref{fig:secciones-rag}.

% --- Grafico resumen

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm]
  % distancia vertical entre pastillas
  \def\step{-1.5}

  % y inicial (arriba)
  \def\y{0}

  \pill{\y}{softcream}{I}{Fundamentos}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softpink}{II}{Arquitectura}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softblue}{III}{Fases de Implementación}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softpeach}{IV}{Paradigmas}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softyellow}{V}{Evaluación y metricas}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softgreen}{VI}{Futuro de RAG}
  
\end{tikzpicture}
\end{center}
\caption{Resumen esquemático de RAG}
\label{fig:secciones-rag}
\end{figure}

A partir de esta hoja de ruta se desarrolla un esquema más detallado, en el que se expone primero exploraremos su teoría, 
características y aplicaciones, como se muestra en la Fig \ref{fig:Fudamentos}. Luego profundizamos en su arquitectura en la cual 
se describe cada uno de los componentes que lo conforman (retriever, augmented y generation) y las variantes y mejoras que existen de cada uno. 
Posteriormente, se detalla el proceso de implementación, desde la preparación de datos hasta el componente de generación, incluyendo las técnicas y herramientas más relevantes.
A continuación en la Fig , se examinan los paradigmas de RAG, dando a conocer los tipos de paradigmas y sus clases, para luego en la Fig , se presentan las métricas y evaluadores automáticos 
utilizados en la evaluación de sistemas RAG, así como las consideraciones éticas y de equidad que deben tenerse en cuenta.
Finalmente, se discuten las tendencias emergentes, los desafíos que actualmente se tienen y futuras direcciones que podrían tomar los sistemas RAG.



% --- Grafico fundamentos
\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm]
\tikzset{
  mindoval/.style={
    rounded corners=18pt,
    draw=black!70,
    line width=0.7pt,
    minimum width=3.2cm,
    minimum height=1.1cm,
    inner sep=6pt,
    fill=white      % <<< todos los nodos en blanco
  },
  mindcenter/.style={
    rounded corners=8pt,
    draw=black!70,
    line width=0.9pt,
    minimum width=3.6cm,
    minimum height=1.1cm,
    inner sep=4pt,
    fill=softrose,  % <<< centro en morado
    font=\bfseries
  },
  mindapp/.style={
    mindoval,
    fill=softblue   % <<< nodo aplicación en azul
  },
  mindarrow/.style={-latex, line width=0.9pt}
}

% --- Nodo central
\node[mindcenter] (fund) at (0,0) {Fundamentos};

% --- Nodos arriba
\node[mindoval] (aport)  at (0,3) {4. Aportes de RAGs};
\node[mindoval] (ragft)  at (5,0) {5. RAG vs fine tuning};

% --- Nodos izquierda
\node[mindoval] (rolrag) at (-5,2.5) {3. Rol de RAG};
\node[mindoval] (qrag)   at (-5,0.75) {2. ¿Qué es RAG?};
\node[mindoval] (qllm)   at (-5,-1.0) {1. ¿Qué es un LLM?};

% --- Nodos abajo
\node[mindapp, minimum width=3.0cm] (apli) at (0,-3.0) {6. Aplicación};
\node[mindoval] (texto)  at (-5,-4.5) {Texto};
\node[mindoval] (img)    at (-2,-6) {Imagen};
\node[mindoval, minimum width=3.6cm] (audio)  at (2,-6) {Audio y video};
\node[mindoval] (codigo) at (5,-4.5) {Código};

% --- Flechas (tocando bordes de nodos)
\draw[mindarrow] (fund.north) -- (aport.south);
\draw[mindarrow] (fund.east) -- (ragft.west);
\draw[mindarrow] (fund.west) -- (rolrag.east);
\draw[mindarrow] (fund.west) -- (qrag.east);
\draw[mindarrow] (fund.west) -- (qllm.east);
\draw[mindarrow] (fund.south) -- (apli.north);

\draw[mindarrow] (apli.west) -- (texto.east);
\draw[mindarrow] (apli) -- (img.north);
\draw[mindarrow] (apli) -- (audio.north);
\draw[mindarrow] (apli.east) -- (codigo.west);

\end{tikzpicture}
\end{center}
\caption{Fundamentos de RAG}
\label{fig:Fudamentos}
\end{figure}

\subsubsection{Fundamentos}
En esta subsección se presentan los fundamentos teóricos de Retrieval Augmented Generation (RAG), 
comenzando con la definición de los modelos de lenguaje de gran escala (LLMs) y su relación. Se expone 
también el papel que desempeña RAG, los principales aportes que ha generado en distintos ámbitos y su diferenciación frente al 
fine tuning. Finalmente, se introduce su aplicación práctica, lo que permite comprender la importancia y el impacto que RAG tiene en 
la actualidad.

\paragraph{Que es un LLM}
Son modelos de inteligencia artificial (IA) basados en la arquitectura transformer, entrenados con grandes volumnes de datos textuales con el objetivo de aprender representaciones
contextuales del lenguaje. Según \textcite{casola2022pretrained}, estos modelos utilizan técnicas de pre-entrenamiento no supervisado para captar patrones lingüísticos y semánticos,
lo que permite que posteriormente puedan ajustarse a tareas específicas como clasificación de texto, análisis de sentimientos, traducción automática, reconocimiento de entidades
o respuesta a preguntas. Ejemplos destacados son \textit{BERT, RoBERTa, ALBERT, XLNet, DistilBERT y GPT-3}, que han mostrado rendimientos sobresalientes en diversas aplicaciones de procesamiento de lenguaje natural (NLP).

De acuerdo con \textcite{ramdurai2025llm}, los LLMs también se definen como una clase de modelos de IA capaces de procesar y generar texto de forma similar al lenguaje humano,
gracias al uso de redes neuronales profundas y la capacidad de aprender no solo gramática y relaciones entre palabras, sino también aspectos más complejos como humor, 
tono emocional y contexto. Entrenados en enormes corpus de datos provenientes de libros, artículos y sitios web, estos modelos pueden responder preguntas, redactar ensayos,
traducir, resumir y crear contenido de manera autónoma. Ejemplos recientes incluyen \textit{GPT-4, T5, XLNet y PaLM}, los cuales demuestran su versatilidad en tareas avanzadas
de NLP y en sistemas aplicados en diferentes industrias. 

\paragraph{Que es un RAG}
Según \textcite{han2024rag}, Retrieval-Augmented Generation (RAG) es una técnica que integra la capacidad generativa de los modelos 
de lenguaje con la precisión de la recuperación de información en tiempo real. En lugar de basarse únicamente en el conocimiento almacenado en
los parámetros durante el entrenamiento, RAG permite consultar repositorios externos como bases de datos o motores de búsqueda para obtener
documentos relevantes y actualizados. Estos se incorporan al prompt del usuario, lo que fundamenta la respuesta en fuentes 
verificables y disminuye los problemas de errores y alucinaciones que suelen presentarse en los modelos de lenguaje de gran escala.  


\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm]
\tikzset{
  mindoval/.style={
    rounded corners=18pt,
    draw=black!70,
    line width=0.7pt,
    minimum width=3.6cm,
    minimum height=1.1cm,
    inner sep=6pt,
    fill=white
  },
  mindcenter/.style={
    rounded corners=8pt,
    draw=black!70,
    line width=0.9pt,
    minimum width=4.0cm,
    minimum height=1.2cm,
    inner sep=4pt,
    fill=softrose,
    font=\bfseries
  },
  mindarrow/.style={-latex, line width=0.9pt}
}

% --- Nodo central
\node[mindcenter] (arquitectura) at (0,0) {Arquitectura};

% --- Nodos conectados
\node[mindoval] (retrieval) at (-5,-3) {Retrieval};
\node[mindoval] (augmented) at (0,-3) {Augmented};
\node[mindoval] (generation) at (5,-3) {Generation};

% --- Flechas
\draw[mindarrow] (arquitectura.south west) -- (retrieval.north);
\draw[mindarrow] (arquitectura.south) -- (augmented.north);
\draw[mindarrow] (arquitectura.south east) -- (generation.north);

\end{tikzpicture}
\end{center}
\caption{Componentes de RAG}
\label{fig:arquitectura_rag}
\end{figure}

\subsubsection{Arquitectura}

RAG se compone de tres fases: recuperación, augmentación y generación. Como lo menciona \textcite{gao2023rag}, primero se 
localizan documentos relevantes para la consulta; luego, se enriquece la entrada del usuario con esos textos; finalmente, el modelo produce 
una respuesta basada tanto en su conocimiento interno como en la información recuperada. Gracias a este enfoque, RAG incrementa la exactitud 
de las respuestas, facilita la actualización del conocimiento sin necesidad de reentrenar el modelo y mejora la transparencia al permitir la 
cita de fuentes. Es una de las técnicas más relevantes en tareas que requieren gran 
cantidad de conocimiento, como el ámbito médico, legal o de investigación científica.  


\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|l|X|}
\hline
\textbf{Categoría} & \textbf{Subcategoría / Tipo} & \textbf{Técnicas} \\ \hline
Indexing & Vector DB & StepBack Prompt \\ \hline
         & Algoritmos de búsqueda & Approximate Nearest Neighbors, Locality-Sensitive Hashing \\ \hline
Enhancements & Reranking & HyDE \\ \hline
             & Retriever Finetuning & - \\ \hline
             & Hybrid Search & - \\ \hline
             & Chunk Optimization & - \\ \hline
             & Recursive Retrieval & - \\ \hline
Tipos de retrievers & Sparse & BM25, TF-IDF \\ \hline
                    & Dense & Embeddings (ej. BERT, OpenAI, etc.) \\ \hline
                    & Others & Modelos híbridos u otros \\ \hline
\end{tabularx}
\caption{Componente Retriever}
\end{table}



\begin{table}[H]
\centering

\begin{tabularx}{\textwidth}{|l|l|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Categoría} & \textbf{Subcategoría / Tipo} & \textbf{Técnicas} \\ \hline
Tipos   & Pre-training  & - \\ \hline
        & Fine-tuning   & - \\ \hline
        & Inference     & - \\ \hline
Data    & Structured    & - \\ \hline
        & Unstructured  & - \\ \hline
        & LLM generated content & - \\ \hline
Process & Once          & - \\ \hline
        & Iterative     & - \\ \hline
        & Adaptative    & - \\ \hline
\end{tabularx}
\caption{Componente Augmentation}
\end{table}

\begin{table}[H]
\centering


\begin{tabularx}{\textwidth}{|l|l|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Categoría} & \textbf{Subcategoría / Tipo} & \textbf{Ejemplos} \\ \hline
Tipos & Transformers & GPT, BART, T5 \\ \hline
      & LSTM         & Modelos secuencia a secuencia tradicionales \\ \hline
      & GANs         & Generación adversarial en imágenes y texto \\ \hline
      & Diffusion Models & Imagen, audio y video \\ \hline
Enhancements & Prompt Engineering & Diseño de instrucciones, chain-of-thought, step-back prompts \\ \hline
             & Generator Fine-tuning & Ajuste del modelo al dominio específico \\ \hline
             & Decoding Tuning & Beam search, nucleus sampling, top-k sampling \\ \hline
\end{tabularx}
\caption{Componente Generator}
\end{table}

\subsubsection{Fases de Implementación}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm]
\tikzset{
  mindoval/.style={
    rounded corners=18pt,
    draw=black!70,
    line width=0.7pt,
    minimum width=3.6cm,
    minimum height=1.1cm,
    inner sep=6pt,
    fill=white
  },
  mindcenter/.style={
    rounded corners=8pt,
    draw=black!70,
    line width=0.9pt,
    minimum width=4.0cm,
    minimum height=1.2cm,
    inner sep=4pt,
    fill=softrose,
    font=\bfseries
  },
  mindarrow/.style={-latex, line width=0.9pt}
}

% --- Nodo central
\node[mindcenter] (paradigmas) at (0,0) {Paradigmas};

% --- Nodos conectados
\node[mindoval, text width=5cm, align=center] 
  (rag) at (-4,-3) {Retrieval-Augmented Generation (RAG)};
\node[mindoval, text width=4.2cm, align=center] 
  (hallucination) at (4,-3) {Hallucination Mitigation};

% --- Flechas
\draw[mindarrow] (paradigmas.south west) -- (rag.north);
\draw[mindarrow] (paradigmas.south east) -- (hallucination.north);

\end{tikzpicture}
\end{center}
\caption{Paradigmas principales en RAG y Hallucination Mitigation}
\label{fig:paradigmas}
\end{figure}

\subsubsection{Paradigmas}
Dentro del area de Retrieval Augmented Generation (RAG) \textcite{gao2023rag} distiguen los paradigmas Naive RAG, Advanced RAG y Modular RAG, que representan un progreso
desde enfoques básicos de recuperación y generación hasta arquitecturas modulares y flexibles. A su vez \textcite{zhang2025hallucination} clasifican los problemas, en el area de 
Hallucination Mitigation, en dos ejes: retrieval failure (fallos en fuentes, consultas o recuperadores ) y generation deficiency 
(ruido o conflicto contextual y límites de capacidad). FInalmente, 
\textcite{zhao2024rag} proponen fundaciones de RAG segun la forma que el retriver complementa al generador se clasifican en Query-based RAG, Latent Representation-based RAG,
Logit-based RAG y Speculative RAG, de esta forma se expande la aplicación de RAG a múltiples dominios y modalidades.


\paragraph{Tipos de Paradigmas}

\begin{itemize}
    \item \textbf{Retrieval-Augmented Generation (RAG) — Gao et al. (2023)}
    \begin{itemize}
        \item Naive RAG: enfoque básico de recuperación y generación.
        \item Advanced RAG: incorpora optimizaciones como segmentación fina, re-ranking y recuperación iterativa.
        \item Modular RAG: paradigma flexible con módulos especializados para búsqueda, memoria, alineación y validación.
    \end{itemize}

    \item \textbf{Tipos de RAG — Zhao et al. (2024)}
    \begin{itemize}
        \item Query-based RAG: integra directamente la consulta y la información recuperada en el input del generador.
        \item Latent Representation-based RAG: incorpora la información recuperada como representaciones latentes en el modelo generativo.
        \item Logit-based RAG: combina la información de recuperación en la fase de decodificación a nivel de logits.
        \item Speculative RAG: sustituye pasos de generación por recuperación para acelerar y reducir costes.
    \end{itemize}

    \item \textbf{Hallucination Mitigation — Zhang \& Zhang (2025)}
    \begin{itemize}
        \item Retrieval failure: fallos en las fuentes, consultas, recuperadores o estrategias de recuperación.
        \item Generation deficiency: deficiencias en la generación como ruido, conflictos contextuales, middle curse, problemas de alineación y límites de capacidad.
    \end{itemize}
\end{itemize}




\subsubsection{Evaluacion y Metricas}

La evaluación de los sistemas de Recuperación de Información (IR) y de Retrieval-Augmented Generation (RAG) ha sido objeto de un creciente interés en la literatura reciente. 
En el ámbito de IR, \textcite{bernard2025fate} destacan que las nociones de equidad, transparencia y responsabilidad requieren enfoques diversos: mientras la \textit{fairness} 
se mide mayormente con métricas automáticas, la \textit{transparency} y la \textit{accountability} suelen evaluarse mediante auditorías y estudios con usuarios. En contraste, 
la dimensión ética carece de métricas claras y se asocia más a aspectos como privacidad y seguridad.  

En el área de RAG, \textcite{knollmeyer2024benchmarking} identifican cinco dimensiones clave de evaluación: relevancia del contexto, fidelidad (\textit{faithfulness}), relevancia 
de la respuesta, corrección y calidad de las citas. Estas dimensiones permiten evaluar de manera más integral los sistemas que combinan recuperación y generación. Asimismo, 
\textcite{gao2023rag} señalan que, además de las métricas automáticas tradicionales de IR (precisión, recall, nDCG), resulta fundamental incluir evaluaciones humanas que capten 
aspectos como coherencia, transparencia y verificabilidad.  

\paragraph{Categorías de Evaluación}
\begin{itemize}
  \item \textbf{Enfoques de Evaluación - Gao et al. (2023)}
        \begin{itemize}
          \item Evaluación independiente por etapas: análisis separado de retrieval, augmentation y generation, con métricas específicas en cada módulo.
          \item Evaluación End-to-End: valoración directa de la salida final del sistema RAG, con dos variantes:
          \begin{itemize}
              \item Evaluación End-to-End automática: frameworks que miden habilidades/abilities clave como exactitud, fidelidad (\textit{faithfulness}), atribución de fuentes, reducción de alucinaciones y transparencia.
              \item Evaluación End-to-End con juicio humano: juicios expertos que valoran coherencia, verificabilidad, utilidad práctica y confianza.
          \end{itemize}
          \item Combinación de métricas: integración de métricas clásicas de recuperación (precisión, recall, nDCG), métricas de generación (coherencia, verificabilidad, calidad narrativa) y evaluación humana.
      \end{itemize}
    \item \textbf{Evaluación en IR con FATE — Bernard \& Balog (2025)}
    \begin{itemize}
        \item Fairness: métricas automáticas como \textit{top-k}, \textit{exposure} y \textit{pairwise metrics}.
        \item Transparency y Accountability: auditorías y estudios de usuarios, centrados en interpretabilidad y trazabilidad.
        \item Ethics: enfoques cualitativos vinculados a privacidad y seguridad.
        \item Tensiones: conflictos entre fairness individual vs. grupal y entre transparencia excesiva vs. carga cognitiva.
    \end{itemize}

    \item \textbf{Evaluación Clásica en IR — Hambarde \& Proença (2023)}
    \begin{itemize}
        \item Métricas de recuperación: precisión, recall, F1, MAP (Mean Average Precision), MRR (Mean Reciprocal Rank).
        \item Métricas de ranking: nDCG (Normalized Discounted Cumulative Gain) y calidad del ordenamiento.
        \item Evaluación de modelos neuronales: comparación con benchmarks tradicionales (TREC, MS MARCO).
        \item Dimensión multi-modal: evaluación de IR en escenarios que integran texto, imágenes y audio.
    \end{itemize}

    \item \textbf{Evaluación en RAG — Knollmeyer et al. (2024); Gao et al. (2023)}
    \begin{itemize}
        \item \textit{Fase de Recuperación}: 
        \begin{itemize}
            \item Context relevance: grado de pertinencia de los documentos recuperados.
            \item Dataset quality: uso de bases de datos curadas y representativas (ej. Wikipedia, MS MARCO).
            \item Métricas aplicadas: precisión, recall, nDCG, cobertura de conocimiento.
        \end{itemize}

        \item \textit{Fase de Generación}: 
        \begin{itemize}
            \item Faithfulness: consistencia factual entre recuperación y generación.
            \item Answer relevance: utilidad de la respuesta respecto a la consulta.
            \item Correctness: exactitud de la información producida y reducción de alucinaciones.
            \item Métricas aplicadas: BLEU, ROUGE, métricas de consistencia factual y evaluaciones humanas.
        \end{itemize}

        \item \textit{Fase de Integración}: 
        \begin{itemize}
            \item Citation quality: precisión, trazabilidad y cobertura de las fuentes citadas.
        \end{itemize}

        \item \textit{Evaluación Global}: 
        \begin{itemize}
            \item Evaluadores mixtos: combinación de métricas automáticas (similaridad semántica, BLEU, ROUGE) con juicios humanos (coherencia, verificabilidad, utilidad práctica).
            \item Datasets: necesidad de colecciones específicas adaptadas a RAG, más allá de benchmarks tradicionales de IR.
        \end{itemize}

        
    \end{itemize}
    
\end{itemize}



\subsubsection{Futuro de RAG}

\paragraph{Desafios Actuales}


\paragraph{Direcciones potenciales}


\paragraph{Perspectivas}

