\chapter{Introducción}

\section{Planteamiento del problema}

\section{Justificación}

\section{Justificación Metodológica}

\section{Objetivos}
\subsection{Objetivo general}
Desarrollar e implementar un sistema RAG que mejore el desempeño del buscador de la plataforma
Centinela, permitiendo recuperar información científica relevante y generar respuestas automáticas
de valor para el usuario.
\subsection{Objetivos específicos}
\begin{itemize}[align=left, label=-]
    \item Realizar una revisión sistemática de la literatura sobre metodologías y/o frameworks para la implementación de RAG.
    \item Diseñar e implementar la arquitectura técnica del sistema RAG utilizando modelos de recuperación y generación de texto.
    \item Evaluar el sistema RAG desarrollado mediante métricas estándar.
\end{itemize}

\section{Alcance}

\section{Marco Teórico}

\section{Revision de literatura}
En los últimos años, la evolución de los modelos de lenguaje de gran escala (Large Language Models, LLM) han redefinido el procesamiento del lenguaje natural
e impulsado nuevas líneas de investigación. 
Sin embargo, estos modelos dependen únicamente de los datos empleados durante su entrenamiento, lo que limita su capacidad para ofrecer respuestas actualizadas, verificables y 
contextualizadas. En respuesta a esta limitación surge el enfoque de Retrieval-Augmented Generation (RAG), el cual combina la recuperación de información con la generación de 
lenguaje natural, logrando mejorar la precisión, la coherencia y la actualidad de las respuestas producidas por los modelos.

Dada la creciente relevancia de los LLM, resulta necesario llevar a cabo una revisión exhaustiva de la literatura que permita consolidar los avances recientes y evaluar los desafíos aún presentes.
En esta sección se presenta un análisis estructurado de la literatura disponible, considerando tanto los fundamentos conceptuales de RAG como sus fases de desarrollo, 
aplicaciones y el futuro. Para ello, el proceso de revisión se organiza en las fases que se presentan a continuación, las cuales buscan garantizar la consistencia, validez 
y pertinencia de la evidencia obtenida.

\subsection{Propósito y objetivos de la revisión}
El propósito de esta revisión es consolidar la información disponible sobre los RAG, abordando su estudio desde los fundamentos hasta las fases de desarrollo. 
Se inicia con su definición y arquitectura, para luego profundizar en las etapas clave del proceso: Extracción del corpus, preprocesamiento, vectorización, recuperación de información, 
evaluación, almacenamiento en bases vectoriales y generación de resultados. Asimismo, se examinan los paradigmas, las métricas de evaluación y el futuro de RAG.
Durante esta revision se busca lograr el objetivo general de proporcionar un panorama global y actualizado sobre los RAG,
exponiendo sus fundamentos, desarrollo y aplicación.

\subsection{Criterios de inclusión y exclusión}
Se incluyen únicamente revisiones sistemáticas y metaanálisis publicados entre 2018 y 2025, en inglés o español, dado que la producción 
científica en el área comenzó a incrementarse a partir de 2018, con base en información de Lens.org\footnote{Es una plataforma abierta
para la búsqueda, análisis y visualización de literatura científica y patentes. Accesible en: \href{https://www.lens.org/}{Lens.org}}, este incremento coincide
con la popularización 
de los modelos de lenguaje basados en transformers\footnote{Se atribuye a hitos como BERT (2018), GPT-2 (2019) y T5 (2020), que impulsaron un avance 
en la investigación del procesamiento del Lenguaje Natural}.
Los estudios deben provenir de fuentes confiables y ser, a su vez, revisados por 
un experto. Se da preferencia a aquellos que presenten una cobertura amplia de los temas más relevantes para el objeto de estudio.  

Se excluyen las revisiones narrativas, los documentos que carezcan de transparencia en sus métodos de búsqueda o síntesis, así como las publicaciones que no estén 
directamente relacionadas con el objeto de estudio delimitado.

\subsection{Identificación del estudio semilla y selección de revisiones relevantes}
El proceso de búsqueda se inicia con la identificación de dos estudios semilla, extraídos de Google Scholar mediante los parámetros “retrieval information” y “retrieval augmented generation”. 
Debido al análisis realizado en Lens.org, se estableció el filtro de 2018 a 2025, ya que se observa que a partir de 2018 el término retrieval-augmented generation 
comenzó a adquirir una relevancia en la literatura científica, mostrando interés de la comunidad investigadora hasta la actualidad.

El primer estudio seleccionado fue Information Retrieval: Recent Advances and Beyond (Hambarde \& Proença, 2023), publicado en IEEE Access. 
Este trabajo constituye una revisión exhaustiva de la recuperación de información, abarcando desde los métodos tradicionales hasta los enfoques 
basados en deep learning y transformers, por lo que resulta un punto de partida principal para explorar la literatura reciente y relevante.

El segundo estudio semilla corresponde al artículo Retrieval-Augmented Generation for Large Language Models (Gao, Xiong, Gao, Jia, Pan, Bi, Dai, Sun \& Wang, 2023), publicado en
arXiv,
el cual presenta un marco conceptual y aplicado sobre la integración de recuperación de información y modelos generativos de gran escala. Su incorporación permite 
establecer una base teórica para contextualizar el análisis de las revisiones seleccionadas.

A partir de estos dos estudios semilla, y aplicando los criterios de inclusión y exclusión previamente definidos, se identificaron \textcolor{blue}{25} revisiones 
relevantes que cumplen con los criterios establecidos. 
Estas revisiones constituyen la base para el análisis y síntesis en el presente trabajo.



\subsection{Valoracion de la evidencias y extracion de la infomacion}
De los estudios seleccionados se procede a realizar un análisis, 
con el fin de excluir aquellos artículos que no cumplen con los criterios establecidos 
o que presentan un nivel de profundidad insuficiente para los objetivos de la revisión. 
La selección final de los estudios se realiza en consenso con expertos en el área, 
garantizando así la pertinencia y relevancia de la evidencia incluida.Para la organización, codificación y síntesis de la 
información se usa ATLAS.ti \footnote{Scientific Software Development GmbH. Disponible en: \href{https://atlasti.com/es}{Atlas.ti}} que facilitará la estructuración de los hallazgos.





% para resuemir la informacion se uso (herramienta) atlas por ejemplo

\subsection{Síntesis y representación de resultados}
Con la literatura seleccionada se identificó la hoja de ruta que se presenta a continuación en la Figura \ref{fig:secciones-rag}.

% --- Grafico resumen

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm]
  % distancia vertical entre pastillas
  \def\step{-1.5}

  % y inicial (arriba)
  \def\y{0}

  \pill{\y}{softcream}{I}{Fundamentos}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softpink}{II}{Arquitectura}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softblue}{III}{Fases de Implementación}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softpeach}{IV}{Paradigmas}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softyellow}{V}{Evaluación y metricas}
  \pgfmathsetmacro\y{\y+\step}
  \pill{\y}{softgreen}{VI}{Futuro de RAG}
  
\end{tikzpicture}
\end{center}
\caption{Resumen esquemático de RAG}
\label{fig:secciones-rag}
\end{figure}

A partir de esta hoja de ruta se desarrolla un esquema más detallado, en el que se expone primero exploraremos su teoría, 
características y aplicaciones, como se muestra en la Fig \ref{fig:Fudamentos}. Luego profundizamos en su arquitectura en la cual 
se describe cada uno de los componentes que lo conforman (retriever, augmented y generation) y las variantes y mejoras que existen de cada uno. 
Posteriormente, se detalla el proceso de implementación, desde la preparación de datos hasta el componente de generación, incluyendo las técnicas y herramientas más relevantes.
A continuación en la Fig , se examinan los paradigmas de RAG, dando a conocer los tipos de paradigmas y sus clases, para luego en la Fig , se presentan las métricas y evaluadores automáticos 
utilizados en la evaluación de sistemas RAG, así como las consideraciones éticas y de equidad que deben tenerse en cuenta.
Finalmente, se discuten las tendencias emergentes, los desafíos que actualmente se tienen y futuras direcciones que podrían tomar los sistemas RAG.



% --- Grafico fundamentos
\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[x=1cm,y=1cm]
\tikzset{
  mindoval/.style={
    rounded corners=18pt,
    draw=black!70,
    line width=0.7pt,
    minimum width=3.2cm,
    minimum height=1.1cm,
    inner sep=6pt,
    fill=white      % <<< todos los nodos en blanco
  },
  mindcenter/.style={
    rounded corners=8pt,
    draw=black!70,
    line width=0.9pt,
    minimum width=3.6cm,
    minimum height=1.1cm,
    inner sep=4pt,
    fill=softrose,  % <<< centro en morado
    font=\bfseries
  },
  mindapp/.style={
    mindoval,
    fill=softblue   % <<< nodo aplicación en azul
  },
  mindarrow/.style={-latex, line width=0.9pt}
}

% --- Nodo central
\node[mindcenter] (fund) at (0,0) {Fundamentos};

% --- Nodos arriba
\node[mindoval] (aport)  at (0,3) {4. Aportes de RAGs};
\node[mindoval] (ragft)  at (5,0) {5. RAG vs fine tuning};

% --- Nodos izquierda
\node[mindoval] (rolrag) at (-5,2.5) {3. Rol de RAG};
\node[mindoval] (qrag)   at (-5,0.75) {2. ¿Qué es RAG?};
\node[mindoval] (qllm)   at (-5,-1.0) {1. ¿Qué es un LLM?};

% --- Nodos abajo
\node[mindapp, minimum width=3.0cm] (apli) at (0,-3.0) {6. Aplicación};
\node[mindoval] (texto)  at (-5,-4.5) {Texto};
\node[mindoval] (img)    at (-2,-6) {Imagen};
\node[mindoval, minimum width=3.6cm] (audio)  at (2,-6) {Audio y video};
\node[mindoval] (codigo) at (5,-4.5) {Código};

% --- Flechas (tocando bordes de nodos)
\draw[mindarrow] (fund.north) -- (aport.south);
\draw[mindarrow] (fund.east) -- (ragft.west);
\draw[mindarrow] (fund.west) -- (rolrag.east);
\draw[mindarrow] (fund.west) -- (qrag.east);
\draw[mindarrow] (fund.west) -- (qllm.east);
\draw[mindarrow] (fund.south) -- (apli.north);

\draw[mindarrow] (apli.west) -- (texto.east);
\draw[mindarrow] (apli) -- (img.north);
\draw[mindarrow] (apli) -- (audio.north);
\draw[mindarrow] (apli.east) -- (codigo.west);

\end{tikzpicture}
\end{center}
\caption{Fundamentos de RAG}
\label{fig:Fudamentos}
\end{figure}

\subsubsection{Fundamentos}
En esta subsección se presentan los fundamentos teóricos de Retrieval Augmented Generation (RAG), 
comenzando con la definición de los modelos de lenguaje de gran escala (LLMs) y su relación. Se expone 
también el papel que desempeña RAG, los principales aportes que ha generado en distintos ámbitos y su diferenciación frente al 
fine tuning. Finalmente, se introduce su aplicación práctica, lo que permite comprender la importancia y el impacto que RAG tiene en 
la actualidad.

\paragraph{Que es un LLM}
Los LLM son modelos de inteligencia artificial (IA) basados en la arquitectura transformer, entrenados con grandes volumnes de datos textuales con el objetivo de aprender representaciones
contextuales del lenguaje. Según \textcite{casola2022pretrained}, estos modelos utilizan técnicas de pre-entrenamiento no supervisado para captar patrones lingüísticos y semánticos,
lo que permite que posteriormente puedan ajustarse a tareas específicas como clasificación de texto, análisis de sentimientos, traducción automática, reconocimiento de entidades
o respuesta a preguntas. Ejemplos destacados son \textit{BERT, RoBERTa, ALBERT, XLNet, DistilBERT y GPT-3}, que han mostrado rendimientos sobresalientes en diversas aplicaciones de procesamiento de lenguaje natural (NLP).

De acuerdo con \textcite{ramdurai2025llm}, los LLMs también se definen como una clase de modelos de IA capaces de procesar y generar texto de forma similar al lenguaje humano,
gracias al uso de redes neuronales profundas y la capacidad de aprender no solo gramática y relaciones entre palabras, sino también aspectos más complejos como humor, 
tono emocional y contexto. Entrenados en enormes corpus de datos provenientes de libros, artículos y sitios web, estos modelos pueden responder preguntas, redactar ensayos,
traducir, resumir y crear contenido de manera autónoma. Ejemplos recientes incluyen \textit{GPT-4, T5, XLNet y PaLM}, los cuales demuestran su versatilidad en tareas avanzadas
de NLP y en sistemas aplicados en diferentes industrias. 

\paragraph{Que es un RAG}
Según \textcite{han2024rag},\textit{Retrieval-Augmented Generation} (RAG) es una técnica que integra la capacidad generativa de los modelos 
de lenguaje con la precisión de la recuperación de información en tiempo real. En lugar de basarse únicamente en el conocimiento almacenado en
los parámetros durante el entrenamiento, RAG permite consultar repositorios externos como bases de datos o motores de búsqueda para obtener
documentos relevantes y actualizados. Estos se incorporan al prompt del usuario, lo que fundamenta la respuesta en fuentes 
verificables y disminuye los problemas de errores y alucinaciones que suelen presentarse en los modelos de lenguaje de gran escala.  

El proceso de RAG se compone de tres fases: recuperación, augmentación y generación. Como lo menciona \textcite{gao2023rag}, primero se 
localizan documentos relevantes para la consulta; luego, se enriquece la entrada del usuario con esos textos; finalmente, el modelo produce 
una respuesta basada tanto en su conocimiento interno como en la información recuperada. Gracias a este enfoque, RAG incrementa la exactitud 
de las respuestas, facilita la actualización del conocimiento sin necesidad de reentrenar el modelo y mejora la transparencia al permitir la 
cita de fuentes. Como lo mencionan estos autores, se ha consolidado como una de las técnicas más relevantes en tareas que requieren gran 
cantidad de conocimiento, como el ámbito médico, legal o de investigación científica.  


\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{|l|l|X|}
\hline
\textbf{Categoría} & \textbf{Subcategoría / Tipo} & \textbf{Técnicas} \\ \hline
Indexing & Vector DB & StepBack Prompt \\ \hline
         & Algoritmos de búsqueda & Approximate Nearest Neighbors, Locality-Sensitive Hashing \\ \hline
Enhancements & Reranking & HyDE \\ \hline
             & Retriever Finetuning & - \\ \hline
             & Hybrid Search & - \\ \hline
             & Chunk Optimization & - \\ \hline
             & Recursive Retrieval & - \\ \hline
Tipos de retrievers & Sparse & BM25, TF-IDF \\ \hline
                    & Dense & Embeddings (ej. BERT, OpenAI, etc.) \\ \hline
                    & Others & Modelos híbridos u otros \\ \hline
\end{tabularx}
\caption{Componente Retriever}
\end{table}



\begin{table}[H]
\centering

\begin{tabularx}{\textwidth}{|l|l|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Categoría} & \textbf{Subcategoría / Tipo} & \textbf{Técnicas} \\ \hline
Tipos   & Pre-training  & - \\ \hline
        & Fine-tuning   & - \\ \hline
        & Inference     & - \\ \hline
Data    & Structured    & - \\ \hline
        & Unstructured  & - \\ \hline
        & LLM generated content & - \\ \hline
Process & Once          & - \\ \hline
        & Iterative     & - \\ \hline
        & Adaptative    & - \\ \hline
\end{tabularx}
\caption{Componente Augmentation}
\end{table}

\begin{table}[H]
\centering


\begin{tabularx}{\textwidth}{|l|l|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Categoría} & \textbf{Subcategoría / Tipo} & \textbf{Ejemplos} \\ \hline
Tipos & Transformers & GPT, BART, T5 \\ \hline
      & LSTM         & Modelos secuencia a secuencia tradicionales \\ \hline
      & GANs         & Generación adversarial en imágenes y texto \\ \hline
      & Diffusion Models & Imagen, audio y video \\ \hline
Enhancements & Prompt Engineering & Diseño de instrucciones, chain-of-thought, step-back prompts \\ \hline
             & Generator Fine-tuning & Ajuste del modelo al dominio específico \\ \hline
             & Decoding Tuning & Beam search, nucleus sampling, top-k sampling \\ \hline
\end{tabularx}
\caption{Componente Generator}
\end{table}

\subsubsection{Arquitectura}
